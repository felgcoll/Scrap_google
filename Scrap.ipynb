{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('INVENTARIO COFRANK CON FORMATO.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marca = df['MARCA'].tolist()\n",
    "modelo = df['MODELO'].tolist()\n",
    "\n",
    "scrap = []\n",
    "for i in range(len(marca)):\n",
    "    if marca[i] not in scrap:\n",
    "        if str(modelo[i]) == 'nan':\n",
    "            scrap.append(str(marca[i]))\n",
    "        else:\n",
    "            scrap.append(str(marca[i])+ ' ' +str(modelo[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(scrap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(directory):\n",
    "    path = r'C:\\Users\\usuario\\Desktop\\Scrap\\\\'+directory\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % path)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in scrap:\n",
    "    create_folder(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_x(search):\n",
    "    site = 'https://www.google.com/search?tbm=isch&q='+search\n",
    "    #providing driver path\n",
    "    driver = webdriver.Firefox(executable_path = 'geckodriver.exe')\n",
    "\n",
    "    #passing site url\n",
    "    driver.get(site)\n",
    "\n",
    "\n",
    "    #if you just want to download 10-15 images then skip the while loop and just write\n",
    "    #driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight)\")\n",
    "\n",
    "\n",
    "    #below while loop scrolls the webpage 7 times(if available)\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    while i<7:  \n",
    "        #for scrolling page\n",
    "        driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight)\")\n",
    "\n",
    "        try:\n",
    "            #for clicking show more results button\n",
    "            driver.find_element_by_xpath(\"/html/body/div[2]/c-wiz/div[3]/div[1]/div/div/div/div/div[5]/input\").click()\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        time.sleep(20)\n",
    "        i+=1\n",
    "\n",
    "    #parsing\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "\n",
    "    #closing web browser\n",
    "    #driver.close()\n",
    "\n",
    "\n",
    "    #scraping image urls with the help of image tag and class used for images\n",
    "    img_tags = soup.find_all(\"img\", class_=\"rg_i\")\n",
    "\n",
    "\n",
    "    count = 0\n",
    "    for i in img_tags:\n",
    "        #print(i['src'])\n",
    "        \n",
    "            try:\n",
    "                #passing image urls one by one and downloading\n",
    "                urllib.request.urlretrieve(i['src'], r'C:\\Users\\usuario\\Desktop\\Scrap\\\\'+seach+'\\\\'+str(count)+\".jpg\")\n",
    "                count+=1\n",
    "                print(\"Number of images downloaded = \"+str(count),end='\\r')\n",
    "            except Exception as e:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for search in scrap:\n",
    "    scrap_x(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
